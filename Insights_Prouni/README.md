# Insights_Prouni

![Descri√ß√£o da Imagem](https://github.com/arlen64/Insights_Prouni/blob/676cb3ded09b08c975b3b7d430ca70a4b4be150f/ImageProject_Prouni.jpeg)

Este √© projeto aprensenta um estudo tendo como base dados do Prouni que visa Extrair informa√ß√µes<br />
de uma base de dados do 'Prouni' que se retrata do detalhamento quantitativo de bolsas concedidas pelo Prouni por ano

## Bibliotecas necess√°rias:

- dash
- ploty
- pandas
- sqlalchemy

## üßê Objetivo

Fazer um processo de etl tendo como base de dados do 'Prouni' que se retrata do detalhamento quantitaivo de bolsas concedidas pelo Prouni. <br/>

## ‚ú® Requisitos do desafio

Esse c√≥digo pode ser usado como base para projetos mais avan√ßados ou para entender os conceitos b√°sicos e intermedi√°rios de processos de ETL. <br/>

Neste desafio, feito em conjunto com o [@arlen64](https://github.com/arlen64), criamos este projeto com a finalidade de realizar processos de "coleta", 'limpeza", "an√°lise" e "visualiza√ß√£o" de dados da **Administra√ß√£o P√∫blica brasileira** tendo como requisitos:

-   Este processo poder√° est√°tico, isto √©, a coleta pode ser feita em apenas uma etapa sem a necessidade de processamento din√¢mico de informa√ß√µes;
-   A coleta normalmente ser√° realizada processando-se um arquivo do tipo `CSV` por meio do uso do `Pandas`;
-   Deve-se realizar um tratamento para remover os dados n√£o relevantes para o fim da aplica√ß√£o ("limpeza").

-   Uso de banco de dados relacional:
    -   Uso do Postgres;
    -   N√£o h√° a necessidade de uso de Spark, bastando o uso de Pandas;
    -   Utilizar comandos SQL ou Python para o cruzamento das informa√ß√µes.
-   Implementar e detalhar um processamento segmentado em no m√≠nimo 3 zonas:
    -   raw (dado cru);
    -   curated (dado limpo); e
    -   analytics (dado analisado).

## Como Usar

Para utilizar este projeto, siga os passos abaixo:

baixar o dataset que disponibilizei no link:<br/> https://dadosabertos.mec.gov.br/images/conteudo/prouni/2020/ProuniRelatorioDadosAbertos2020.csv<br/> e em seguida crie tr√™s banco de dados de forma manual no postgres. sendo eles: <br/>
raw_data, silver_data, gold_data. Por fim, passe as refer√™ncias do seu banco de dados e o caminho do arquivo csv que foi baixado para o script python.

## üõ† Tecnologias

#### **Depend√™ncias**

-   **[Python](https://docs.python.org/pt-br/3/tutorial/index.html)**
-   **[Poetry - Python dependency management and packaging made easy](https://python-poetry.org/)**
-   **[Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/index.html)**
-   **[PostgreSQL: The world's most advanced open source database](https://www.postgresql.org/)**
-   **[Plotly Python Graphing Library](https://plotly.com/python/)**
-   **[Dash for Python | Plotly](https://dash.plotly.com/tutorial)**
-   **[jupyter for VsCode | Plotly](https://www.walissonsilva.com/posts/jupyter-notebook-no-visual-studio-code)**

### Resultado:

Carregamento dos dados brutos no banco de dados raw_data do postgres, carregar os dados tratados no banco silver_data e os gr√°ficos escolhidos no banco gold_data <br/>
os dados ser√£o consultados do banco silver_data para sim gerar as tabelas e os gr√°ficos com as bibliotecas dash e plotly. Diante disso, ser√£o gerados 6 gr√°ficos com suas regras de neg√≥cios de exemplo <br/>
e ao fim do c√≥digo a constru√ß√£o de um dashboard com todos os gr√°ficos em uma p√°gina local.
